{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPD3aMdeluxYYowgQe1czOn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galerez89/nlp_tokenization_project/blob/master/prepare-iwslt14.sh\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30XKNN-QEUZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env bash\n",
        "#\n",
        "# Adapted from https://github.com/facebookresearch/MIXER/blob/master/prepareData.sh\n",
        "\n",
        "echo 'Cloning Moses github repository (for tokenization scripts)...'\n",
        "git clone https://github.com/moses-smt/mosesdecoder.git\n",
        "\n",
        "echo 'Cloning Subword NMT repository (for BPE pre-processing)...'\n",
        "git clone https://github.com/rsennrich/subword-nmt.git\n",
        "\n",
        "SCRIPTS=mosesdecoder/scripts\n",
        "TOKENIZER=tokenizerv2.perl\n",
        "LC=$SCRIPTS/tokenizer/lowercase.perl\n",
        "CLEAN=$SCRIPTS/training/clean-corpus-n.perl\n",
        "BPEROOT=subword-nmt/subword_nmt\n",
        "BPE_TOKENS=10000\n",
        "\n",
        "URL=\"https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\"\n",
        "GZ=de-en.tgz\n",
        "\n",
        "if [ ! -d \"$SCRIPTS\" ]; then\n",
        "    echo \"Please set SCRIPTS variable correctly to point to Moses scripts.\"\n",
        "    exit\n",
        "fi\n",
        "\n",
        "src=de\n",
        "tgt=en\n",
        "lang=de-en\n",
        "prep=iwslt14.tokenized.de-en\n",
        "tmp=$prep/tmp\n",
        "orig=orig\n",
        "\n",
        "mkdir -p $orig $tmp $prep\n",
        "\n",
        "echo \"Downloading data from ${URL}...\"\n",
        "cd $orig\n",
        "wget \"$URL\"\n",
        "\n",
        "if [ -f $GZ ]; then\n",
        "    echo \"Data successfully downloaded.\"\n",
        "else\n",
        "    echo \"Data not successfully downloaded.\"\n",
        "    exit\n",
        "fi\n",
        "\n",
        "tar zxvf $GZ\n",
        "cd ..\n",
        "\n",
        "echo \"pre-processing train data...\"\n",
        "for l in $src $tgt; do\n",
        "    f=train.tags.$lang.$l\n",
        "    tok=train.tags.$lang.tok.$l\n",
        "\n",
        "    cat $orig/$lang/$f | \\\n",
        "    grep -v '<url>' | \\\n",
        "    grep -v '<talkid>' | \\\n",
        "    grep -v '<keywords>' | \\\n",
        "    sed -e 's/<title>//g' | \\\n",
        "    sed -e 's/<\\/title>//g' | \\\n",
        "    sed -e 's/<description>//g' | \\\n",
        "    sed -e 's/<\\/description>//g' | \\\n",
        "    perl $TOKENIZER -threads 8 -l $l > $tmp/$tok\n",
        "    echo \"\"\n",
        "done\n",
        "perl $CLEAN -ratio 1.5 $tmp/train.tags.$lang.tok $src $tgt $tmp/train.tags.$lang.clean 1 175\n",
        "for l in $src $tgt; do\n",
        "    perl $LC < $tmp/train.tags.$lang.clean.$l > $tmp/train.tags.$lang.$l\n",
        "done\n",
        "\n",
        "echo \"pre-processing valid/test data...\"\n",
        "for l in $src $tgt; do\n",
        "    for o in `ls $orig/$lang/IWSLT14.TED*.$l.xml`; do\n",
        "    fname=${o##*/}\n",
        "    f=$tmp/${fname%.*}\n",
        "    echo $o $f\n",
        "    grep '<seg id' $o | \\\n",
        "        sed -e 's/<seg id=\"[0-9]*\">\\s*//g' | \\\n",
        "        sed -e 's/\\s*<\\/seg>\\s*//g' | \\\n",
        "        sed -e \"s/\\â€™/\\'/g\" | \\\n",
        "    perl $TOKENIZER -threads 8 -l $l | \\\n",
        "    perl $LC > $f\n",
        "    echo \"\"\n",
        "    done\n",
        "done\n",
        "\n",
        "\n",
        "echo \"creating train, valid, test...\"\n",
        "for l in $src $tgt; do\n",
        "    awk '{if (NR%23 == 0)  print $0; }' $tmp/train.tags.de-en.$l > $tmp/valid.$l\n",
        "    awk '{if (NR%23 != 0)  print $0; }' $tmp/train.tags.de-en.$l > $tmp/train.$l\n",
        "\n",
        "    cat $tmp/IWSLT14.TED.dev2010.de-en.$l \\\n",
        "        $tmp/IWSLT14.TEDX.dev2012.de-en.$l \\\n",
        "        $tmp/IWSLT14.TED.tst2010.de-en.$l \\\n",
        "        $tmp/IWSLT14.TED.tst2011.de-en.$l \\\n",
        "        $tmp/IWSLT14.TED.tst2012.de-en.$l \\\n",
        "        > $tmp/test.$l\n",
        "done\n",
        "\n",
        "TRAIN=$tmp/train.en-de\n",
        "BPE_CODE=$prep/code\n",
        "rm -f $TRAIN\n",
        "for l in $src $tgt; do\n",
        "    cat $tmp/train.$l >> $TRAIN\n",
        "done\n",
        "\n",
        "echo \"learn_bpe.py on ${TRAIN}...\"\n",
        "python $BPEROOT/learn_bpe.py -s $BPE_TOKENS < $TRAIN > $BPE_CODE\n",
        "\n",
        "for L in $src $tgt; do\n",
        "    for f in train.$L valid.$L test.$L; do\n",
        "        echo \"apply_bpe.py to ${f}...\"\n",
        "        python $BPEROOT/apply_bpe.py -c $BPE_CODE < $tmp/$f > $prep/$f\n",
        "    done\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}